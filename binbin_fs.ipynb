{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, sys, os, errno\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] %(name)s: %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_handlers = {}\n",
    "def command_handler(f):\n",
    "    command_handlers[f.__name__] = f\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_samples_by_class(matrix, sample_classes, positive_class=None, negative_class=None):\n",
    "    '''\n",
    "    Args:\n",
    "        matrix: \n",
    "            pandas DataFrame: [n_samples, n_features]\n",
    "        sample_classes: \n",
    "            pandas Series. Index are sample ids. Values are sample classes.\n",
    "    Returns:\n",
    "        X: pandas DataFrame\n",
    "        y: ndarray\n",
    "    '''\n",
    "    if (positive_class is not None) and (negative_class is not None):\n",
    "        positive_class = positive_class.split(',')\n",
    "        negative_class = negative_class.split(',')\n",
    "    else:\n",
    "        unique_classes = np.unique(sample_classes.values)\n",
    "        if len(unique_classes) != 2:\n",
    "            raise ValueError('expect 2 classes but {} classes found'.format(len(unique_classes)))\n",
    "        positive_class, negative_class = unique_classes\n",
    "    positive_class = np.atleast_1d(positive_class)\n",
    "    negative_class = np.atleast_1d(negative_class)\n",
    "\n",
    "    logger.info('positive class: {}, negative class: {}'.format(positive_class, negative_class))\n",
    "    X_pos = matrix.loc[sample_classes[sample_classes.isin(positive_class)].index.values]\n",
    "    X_neg = matrix.loc[sample_classes[sample_classes.isin(negative_class)].index.values]\n",
    "    logger.info('number of positive samples: {}, negative samples: {}, class ratio: {}'.format(\n",
    "        X_pos.shape[0], X_neg.shape[0], float(X_pos.shape[0])/X_neg.shape[0]))\n",
    "    X = pd.concat([X_pos, X_neg], axis=0)\n",
    "    y = np.zeros(X.shape[0], dtype=np.int32)\n",
    "    y[X_pos.shape[0]:] = 1\n",
    "    del X_pos\n",
    "    del X_neg\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@command_handler\n",
    "def preprocess_features(args):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "    logger.info('read feature matrix: ' + args.matrix)\n",
    "    X = pd.read_table(args.matrix, index_col=0, sep='\\t')\n",
    "    if args.transpose:\n",
    "        logger.info('transpose feature matrix')\n",
    "        X = X.T\n",
    "    logger.info('{} samples, {} features'.format(X.shape[0], X.shape[1]))\n",
    "    if args.remove_zero_features is not None:\n",
    "        logger.info('remove features with zero fraction larger than {}'.format(args.remove_zero_features))\n",
    "        X = X.loc[:, ~(np.isclose(X, 0).sum(axis=0) > (X.shape[0]*args.remove_zero_features))]\n",
    "    if args.rpkm_top is not None:\n",
    "        logger.info('select top {} features ranked by RPKM'.format(args.rpkm_top))\n",
    "        feature_info = X.columns.to_series().str.split('|', expand=True)\n",
    "        feature_info.columns = ['gene_id', 'gene_type', 'gene_name', 'feature_id', 'transcript_id', 'start', 'end']\n",
    "        feature_info['start'] = feature_info['start'].astype('int')\n",
    "        feature_info['end'] = feature_info['end'].astype('int')\n",
    "        feature_info['length'] = feature_info['end'] - feature_info['start']\n",
    "        rpkm = 1e3*X.div(feature_info['length'], axis=1)\n",
    "        mean_rpkm = np.exp(np.log(rpkm + 0.01).mean(axis=0)) - 0.01\n",
    "        features_select = mean_rpkm.sort_values(ascending=False)[:args.rpkm_top].index.values\n",
    "        X = X.loc[:, features_select]\n",
    "    elif args.expr_top is not None:\n",
    "        logger.info('select top {} features ranked by raw expression value'.format(args.expr_top))\n",
    "        mean_expr = np.exp(np.log(X + 0.01).mean(axis=0)) - 0.01\n",
    "        features_select = mean_expr.sort_values(ascending=False)[:args.expr_top].index.values\n",
    "        X = X.loc[:, features_select]\n",
    "\n",
    "    feature_names = X.columns.values\n",
    "    logger.info('{} samples, {} features'.format(X.shape[0], X.shape[1]))\n",
    "    logger.info('sample: {} ...'.format(str(X.index.values[:3])))\n",
    "    logger.info('features: {} ...'.format(str(X.columns.values[:3])))\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    sample_ids = X.index.values\n",
    "\n",
    "    if args.use_log:\n",
    "        logger.info('apply log2 to feature matrix')\n",
    "        X = np.log2(X + 0.001)\n",
    "\n",
    "    if args.scaler == 'zscore':\n",
    "        logger.info('scale features using z-score normalization')\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    elif args.scaler == 'robust':\n",
    "        logger.info('scale features using robust normalization')\n",
    "        X = RobustScaler().fit_transform(X)\n",
    "    elif args.scaler == 'min_max':\n",
    "        logger.info('scale features using min-max normalization')\n",
    "        X = MinMaxScaler().fit_transform(X)\n",
    "    elif args.scaler == 'max_abs':\n",
    "        logger.info('scale features using max-abs normalization')\n",
    "        X = MaxAbsScaler().fit_transform(X)\n",
    "    \n",
    "    X = pd.DataFrame(X, index=sample_ids, columns=feature_names)\n",
    "    X.index.name = 'sample'\n",
    "    X.to_csv(args.output_file, sep='\\t', header=True, index=True, na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting estimators\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/6c/ee058363a0ca44c18eb3b71010cdd479be1beeedbe23ec2ecf11b97d266d/estimators-0.1.0.dev0-py2.py3-none-any.whl\n",
      "Collecting pympler==0.4.3 (from estimators)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7c/4d/7da5db3fa5939f661b92d46b3918ae57449a8522507e6562c586a7491d0e/Pympler-0.4.3.tar.gz (166kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 14.1MB/s a 0:00:01\n",
      "\u001b[?25hCollecting SQLAlchemy==1.0.15 (from estimators)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/7d/f230ac50198cfe3cdc957c3572a18dc92600047ce707b5b923c56ab92c1b/SQLAlchemy-1.0.15.tar.gz (4.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.8MB 7.3MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pympler, SQLAlchemy\n",
      "  Running setup.py bdist_wheel for pympler ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/xieyufeng/.cache/pip/wheels/a8/ad/2b/54e351332ede9b499a9605b9089d5f610c75bd5dc79a462af8\n",
      "  Running setup.py bdist_wheel for SQLAlchemy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/xieyufeng/.cache/pip/wheels/c1/9b/33/73800219ae4afd911c5329acdbc889512b37abba8cfb75ceb5\n",
      "Successfully built pympler SQLAlchemy\n",
      "\u001b[31mjupyterhub 0.8.1 has requirement SQLAlchemy>=1.1, but you'll have sqlalchemy 1.0.15 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pympler, SQLAlchemy, estimators\n",
      "  Found existing installation: SQLAlchemy 1.2.1\n",
      "    Uninstalling SQLAlchemy-1.2.1:\n",
      "      Successfully uninstalled SQLAlchemy-1.2.1\n",
      "Successfully installed SQLAlchemy-1.0.15 estimators-0.1.0.dev0 pympler-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xieyufeng/ex\n"
     ]
    }
   ],
   "source": [
    "cd ~/ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd7160b34834d2a9013994c1f0c63dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('scirep', 'exorbase', 'exosome_small', 'pico_3v3'), value='scirep'), Dropdown(description='sequencing_type', options=('short', 'long', 'domain_only', 'transcript'), value='short'), Dropdown(description='classifier', options=('logistic_regression', 'linear_svm', 'random_forest', 'decision_tree', 'logistic_regression_l1'), value='logistic_regression'), Dropdown(description='value_change', options=('any', 'up', 'down'), value='any'), Dropdown(description='example_cancer', options=('Normal-CRC', 'Normal-PAAD', 'Normal-PRAD', 'Normal-HCC'), value='Normal-CRC'), Dropdown(description='reads_preprocess', options=(True, False), value=True), Dropdown(description='stage_info', options=('No Stage', 'With Stage'), value='No Stage'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('scirep',\n",
       " 'short',\n",
       " 'logistic_regression',\n",
       " 'any',\n",
       " 'domains_combined',\n",
       " 'Normal-CRC',\n",
       " True,\n",
       " 'No Stage')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact,interactive, FloatSlider,IntSlider, RadioButtons,Dropdown,Tab,Text\n",
    "def interactive_config_settings(dataset,sequencing_type,classifier,value_change,example_cancer,reads_preprocess,stage_info):\n",
    "    if sequencing_type == 'short':\n",
    "        exp_mx_name = 'domains_combined'\n",
    "    elif sequencing_type =='long':\n",
    "        exp_mx_name = 'featurecounts'\n",
    "    elif sequencing_type =='domain_only':\n",
    "        exp_mx_name = 'domains_long'\n",
    "    elif sequencing_type =='transcript':\n",
    "        exp_mx_name = 'transcript'\n",
    "    return dataset,sequencing_type,classifier,value_change,exp_mx_name,example_cancer,reads_preprocess,stage_info\n",
    "\n",
    "widget =interactive(interactive_config_settings,\n",
    "           dataset= ['scirep','exorbase','exosome_small','pico_3v3'],\n",
    "           sequencing_type=['short','long','domain_only','transcript'],\n",
    "           classifier = ['logistic_regression','linear_svm','random_forest','decision_tree','logistic_regression_l1'],\n",
    "           value_change = ['any','up','down'],\n",
    "        example_cancer=['Normal-CRC','Normal-PAAD','Normal-PRAD','Normal-HCC'],\n",
    "                   reads_preprocess=[True,False],\n",
    "                   stage_info = ['No Stage','With Stage'])  # if start from preprocessing\n",
    "display(widget)\n",
    "dataset,sequencing_type,classifier_use,value_change,exp_mx_name,example_cancer,reads_preprocess,stage_info = widget.result\n",
    "dataset,sequencing_type,classifier_use,value_change,exp_mx_name,example_cancer,reads_preprocess,stage_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mx_file = 'output/'+dataset+'/count_matrix/'+exp_mx_name+'.txt'\n",
    "original_mx = pd.read_table(original_mx_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hsa-let-7a-2-3p|miRNA|hsa-let-7a-2-3p|hsa-let-7a-2-3p|hsa-let-7a-2-3p|0|22',\n",
       "       'hsa-let-7a-3p|miRNA|hsa-let-7a-3p|hsa-let-7a-3p|hsa-let-7a-3p|0|21',\n",
       "       'hsa-let-7a-5p|miRNA|hsa-let-7a-5p|hsa-let-7a-5p|hsa-let-7a-5p|0|22',\n",
       "       ...,\n",
       "       'chrY_24209980_24210020_-|genomic|chrY_24209980_24210020_-|peak_5476|chrY|24209980|24210020',\n",
       "       'chrY_25460120_25460160_+|genomic|chrY_25460120_25460160_+|peak_5477|chrY|25460120|25460160',\n",
       "       'chrY_26274560_26274620_-|genomic|chrY_26274560_26274620_-|peak_5478|chrY|26274560|26274620'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = original_mx.T\n",
    "feature_names = m.columns.values\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='scirep':\n",
    "    if stage_info =='No Stage':\n",
    "        class_info = 'data/'+dataset+'/sample_classes.no_stage.txt'\n",
    "    else:\n",
    "        class_info = 'data/'+dataset+'/sample_classes.txt'\n",
    "\n",
    "sample_classes = pd.read_table(class_info,sep='\\t',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_id\n",
       "Sample_1S3      Colorectal Cancer\n",
       "Sample_1S6      Colorectal Cancer\n",
       "Sample_1S9      Colorectal Cancer\n",
       "Sample_1S12     Colorectal Cancer\n",
       "Sample_1S15     Colorectal Cancer\n",
       "Sample_1S18     Colorectal Cancer\n",
       "Sample_1S21     Colorectal Cancer\n",
       "Sample_1S24     Colorectal Cancer\n",
       "Sample_4S2      Colorectal Cancer\n",
       "Sample_4S5      Colorectal Cancer\n",
       "Sample_4S8      Colorectal Cancer\n",
       "Sample_4S11     Colorectal Cancer\n",
       "Sample_4S14     Colorectal Cancer\n",
       "Sample_4S17     Colorectal Cancer\n",
       "Sample_4S20     Colorectal Cancer\n",
       "Sample_4S23     Colorectal Cancer\n",
       "Sample_N1         Healthy Control\n",
       "Sample_N7         Healthy Control\n",
       "Sample_N13        Healthy Control\n",
       "Sample_N19        Healthy Control\n",
       "Sample_N25        Healthy Control\n",
       "Sample_N31        Healthy Control\n",
       "Sample_N37        Healthy Control\n",
       "Sample_N43        Healthy Control\n",
       "Sample_2S1      Colorectal Cancer\n",
       "Sample_2S4      Colorectal Cancer\n",
       "Sample_2S7      Colorectal Cancer\n",
       "Sample_2S10     Colorectal Cancer\n",
       "Sample_2S13     Colorectal Cancer\n",
       "Sample_2S16     Colorectal Cancer\n",
       "                      ...        \n",
       "Sample_Pan04    Pancreatic Cancer\n",
       "Sample_PC5        Prostate Cancer\n",
       "Sample_PC11       Prostate Cancer\n",
       "Sample_PC17       Prostate Cancer\n",
       "Sample_PC25       Prostate Cancer\n",
       "Sample_PC35       Prostate Cancer\n",
       "Sample_1S2      Colorectal Cancer\n",
       "Sample_1S5      Colorectal Cancer\n",
       "Sample_1S8      Colorectal Cancer\n",
       "Sample_1S11     Colorectal Cancer\n",
       "Sample_1S14     Colorectal Cancer\n",
       "Sample_1S17     Colorectal Cancer\n",
       "Sample_1S20     Colorectal Cancer\n",
       "Sample_1S23     Colorectal Cancer\n",
       "Sample_1S25     Colorectal Cancer\n",
       "Sample_4S1      Colorectal Cancer\n",
       "Sample_4S4      Colorectal Cancer\n",
       "Sample_4S7      Colorectal Cancer\n",
       "Sample_4S10     Colorectal Cancer\n",
       "Sample_4S13     Colorectal Cancer\n",
       "Sample_4S16     Colorectal Cancer\n",
       "Sample_4S19     Colorectal Cancer\n",
       "Sample_4S22     Colorectal Cancer\n",
       "Sample_4S25     Colorectal Cancer\n",
       "Sample_N49        Healthy Control\n",
       "Sample_Pan05    Pancreatic Cancer\n",
       "Sample_Pan06    Pancreatic Cancer\n",
       "Sample_PC6        Prostate Cancer\n",
       "Sample_PC12       Prostate Cancer\n",
       "Sample_PC26       Prostate Cancer\n",
       "Name: label, Length: 192, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_classes = sample_classes.iloc[:, 0]\n",
    "sample_classes = sample_classes.loc[m.index.values]\n",
    "sample_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Colorectal Cancer', 'Prostate Cancer']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_class = 'Colorectal Cancer,Prostate Cancer'\n",
    "negative_class = 'Healthy Control'\n",
    "positive_class = positive_class.split(',')\n",
    "positive_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = 'Colorectal Cancer'\n",
    "negative_class = 'Healthy Control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = np.atleast_1d(positive_class)\n",
    "negative_class = np.atleast_1d(negative_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = m.loc[sample_classes[sample_classes.isin(positive_class)].index.values]\n",
    "X_neg = m.loc[sample_classes[sample_classes.isin(negative_class)].index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_pos, X_neg], axis=0)\n",
    "y = np.zeros(X.shape[0], dtype=np.int32)\n",
    "y[X_pos.shape[0]:] = 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "sample_ids = X.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,  283, 2460, ...,   16,   25,   16],\n",
       "       [  14,  503, 6617, ...,    7,    9,   32],\n",
       "       [   3,  214, 2140, ...,   11,   17,   14],\n",
       "       ...,\n",
       "       [   7,  655, 7057, ...,    1,    1,   13],\n",
       "       [  18,  531, 5808, ...,    5,    7,   12],\n",
       "       [  11,  837, 7514, ...,    2,    4,    8]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 100.0, 1000.0, 10000.0, 100000.0]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = None\n",
    "grid_search = None\n",
    "estimator = LogisticRegression()\n",
    "grid_search = {'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4, 1e5]}\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = KFold(n_splits=5)\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.full((splitter.get_n_splits(X), X.shape[0]), np.nan)\n",
    "predicted_labels = np.full((splitter.get_n_splits(X), X.shape[0]), np.nan)\n",
    "train_index_matrix = np.zeros((splitter.get_n_splits(X), X.shape[0]),dtype=np.bool)\n",
    "feature_selection_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19241"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selection_matrix = np.zeros((splitter.get_n_splits(X), X.shape[1]), dtype=bool)\n",
    "feature_selection_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_step = 0.5\n",
    "rfe_step = int(max(1, rfe_step*n_features))\n",
    "rfe_scores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_split = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scorer = roc_auc_score\n",
    "data_splits = list(splitter.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits.append((np.arange(n_samples), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
       "         47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,\n",
       "         77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89, 120,\n",
       "         121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149]),\n",
       "  array([ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "         103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "         116, 117, 118, 119])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119]),\n",
       "  array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "         146, 147, 148, 149])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149]), None)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?fold/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:00<00:00, 58.52fold/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in tqdm(data_splits, total=splitter.get_n_splits(X) + 1, unit='fold'):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 100.0, 1000.0, 10000.0, 100000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = GridSearchCV(estimator, grid_search, cv=5)\n",
    "cv.fit(X[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,  50])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "       0.75, 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ,\n",
       "       1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ,\n",
       "       1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ,\n",
       "       1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ,\n",
       "       1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "compute_sample_weight('balanced', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=10, step=0.5, verbose=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(estimator, n_features_to_select=10, step=0.5)\n",
    "rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(estimator, features)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_score = lambda estimator, features: scorer(y_test, \n",
    "                            score_function(estimator)(X[test_index][:, features])[:, 1])\n",
    "step_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(estimator):\n",
    "    '''Get method of an estimator that predict a continous score for each sample\n",
    "    '''\n",
    "    if hasattr(estimator, 'predict_proba'):\n",
    "        return estimator.predict_proba\n",
    "    elif hasattr(estimator, 'decision_function'):\n",
    "        return estimator.decision_function\n",
    "    else:\n",
    "        raise ValueError('the estimator should either have decision_function() method or predict_proba() method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(estimator, 'predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(estimator, 'decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00034662])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict_proba(X[test_index][:, 1])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14,  503, 6617, ...,    7,    9,   32]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[test_index][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99653377e-01, 3.46622868e-04]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_function(estimator)(X[test_index][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 150 is out of bounds for axis 1 with size 150",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-b163dd8f66b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/apps/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# that have not been eliminated yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0msupport_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mranking_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-0aea813c5e35>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(estimator, features)\u001b[0m\n\u001b[1;32m      1\u001b[0m step_score = lambda estimator, features: scorer(y_test, \n\u001b[0;32m----> 2\u001b[0;31m                             score_function(estimator)(X[test_index][:, features])[:, 1])\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 150 is out of bounds for axis 1 with size 150"
     ]
    }
   ],
   "source": [
    "rfe._fit(X_train, y_train, step_score=step_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RFE' object has no attribute 'ranking_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-a1d14715f9a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RFE' object has no attribute 'ranking_'"
     ]
    }
   ],
   "source": [
    "np.nonzero(rfe.ranking_ == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-10ebe34c4496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read feature matrix: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, get_scorer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, LeaveOneOut, \\\n",
    "    RepeatedKFold, RepeatedStratifiedKFold, LeaveOneOut, StratifiedShuffleSplit\n",
    "import pickle\n",
    "#from estimators import RobustEstimator\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "\n",
    "\n",
    "    # select samples\n",
    "if (args.positive_class is not None) and (args.negative_class is not None):\n",
    "    positive_class = args.positive_class.split(',')\n",
    "    negative_class = args.negative_class.split(',')\n",
    "else:\n",
    "    unique_classes = np.unique(sample_classes.values)\n",
    "    if len(unique_classes) != 2:\n",
    "        raise ValueError('expect 2 classes but {} classes found'.format(len(unique_classes)))\n",
    "    positive_class, negative_class = unique_classes\n",
    "positive_class = np.atleast_1d(positive_class)\n",
    "negative_class = np.atleast_1d(negative_class)\n",
    "\n",
    "\n",
    "\n",
    "if args.method == 'logistic_regression':\n",
    "    estimator = LogisticRegression()\n",
    "    grid_search = {'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4, 1e5]}\n",
    "elif args.method == 'random_forest':\n",
    "    estimator = RandomForestClassifier()\n",
    "    grid_search = {'n_estimators': [25, 50, 75], 'max_depth': list(range(2, 8)) }\n",
    "elif args.method == 'linear_svm':\n",
    "    estimator = LinearSVC()\n",
    "    grid_search = {'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4, 1e5]}\n",
    "else:\n",
    "    raise ValueError('unknown feature selection method: {}'.format(args.method))\n",
    "\n",
    "def get_splitter(splitter, n_splits=5, n_repeats=5, test_size=0.2):\n",
    "    if splitter == 'kfold':\n",
    "        return KFold(n_splits=n_splits)\n",
    "    elif splitter == 'stratified_kfold':\n",
    "        return StratifiedKFold(n_splits=n_splits)\n",
    "    elif splitter == 'repeated_stratified_kfold':\n",
    "        return RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    elif splitter == 'shuffle_split':\n",
    "        return ShuffleSplit(n_splits=n_splits, test_size=test_size)\n",
    "    elif splitter == 'stratified_shuffle_split':\n",
    "        return StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size)\n",
    "    elif splitter == 'leave_one_out':\n",
    "        return LeaveOneOut()\n",
    "    else:\n",
    "        raise ValueError('unknown splitter: {}'.format(splitter))\n",
    "\n",
    "def score_function(estimator):\n",
    "    '''Get method of an estimator that predict a continous score for each sample\n",
    "    '''\n",
    "    if hasattr(estimator, 'predict_proba'):\n",
    "        return estimator.predict_proba\n",
    "    elif hasattr(estimator, 'decision_function'):\n",
    "        return estimator.decision_function\n",
    "    else:\n",
    "        raise ValueError('the estimator should either have decision_function() method or predict_proba() method')\n",
    "\n",
    "def feature_importances(estimator):\n",
    "    '''Get feature importance attribute of an estimator\n",
    "    '''\n",
    "    if hasattr(estimator, 'coef_'):\n",
    "        return np.ravel(estimator.coef_)\n",
    "    elif hasattr(estimator, 'feature_importances_'):\n",
    "        return np.ravel(estimator.feature_importances_)\n",
    "    else:\n",
    "        raise ValueError('the estimator should have either coef_ or feature_importances_ attribute')\n",
    "\n",
    "def get_scorer(scoring):\n",
    "    if scoring == 'roc_auc':\n",
    "        return roc_auc_score\n",
    "    else:\n",
    "        raise ValueError('unknonwn scoring: {}'.format(scoring))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=2, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=2)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_splits': 2, 'shuffle': False, 'random_state': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x7faea325eca8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
